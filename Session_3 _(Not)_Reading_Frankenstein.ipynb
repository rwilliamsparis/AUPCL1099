{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cdb3141",
   "metadata": {},
   "source": [
    "# (Not) Reading Frankenstein\n",
    "\n",
    "*This Notebook was prepared by Russell Williams, but the real under-the-bonnet preparation  work was done by Ruth Corran. We both work at the American University of Paris. \n",
    "\n",
    "Today we are thinking about manipulating and asking questions of full literary texts in the notebooks. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7074bdd",
   "metadata": {},
   "source": [
    "# Part 1\n",
    "\n",
    "Here we'll start by asking some simple questions, recapping the some of the work at the end of the Session Two notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef59f0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "with urllib.request.urlopen(\"https://raw.githubusercontent.com/rwilliamsparis/AUPCL1099/main/corpora/FrankensteinLetters.txt\") as f:\n",
    "    frank_text=f.read().decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d376e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(frank_text[:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabb865b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_sents(string):\n",
    "    num_sents = string.count('.') + string.count('?') + string.count('!')\n",
    "    return num_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039cf6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_words(string):\n",
    "    return string.count(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82af499",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_per_sent(string):\n",
    "    num_sents = get_num_sents(string)\n",
    "    num_words = get_num_words(string)\n",
    "    return num_words / num_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8177d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_words_per_sent(frank_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0231fea1",
   "metadata": {},
   "source": [
    "Your challenge is to use your coding skills to calculate the average number of words per sentence in Cat Person and the opening four chapters of Dracula. (Meaningless bonus points awarded if you are able to provide an analysis of an alternative text...). Use the following empty cell to experiment (or create some more)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affbb232",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044dbb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we'll import some tools that will tell the notebook how to perform some numerical analysis\n",
    "\n",
    "# numpy is your basic numerical analysis package for Python\n",
    "# np is shorthand for numpy\n",
    "import numpy as np\n",
    "\n",
    "# matplotlib allows us to plot graphs. Here 'fivethirtyeight' is the style guide: https://matplotlib.org/stable/gallery/style_sheets/fivethirtyeight.html \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plots\n",
    "plots.style.use('fivethirtyeight')\n",
    "\n",
    "# pandas is python numerical data science. It allows us to construct dataframes: https://pandas.pydata.org/docs/user_guide/10min.html#min\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed82559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're going to be working initially with Mary Shelley's Frankenstein, as available in Project Gutenberg, so we need to pull that into the notebook for analysis\n",
    "\n",
    "# This allows me to import URLs and the instructions allow the text to be read and cleaned up:\n",
    "\n",
    "from urllib.request import urlopen \n",
    "import re\n",
    "def read_url(url): \n",
    "    return re.sub('\\\\s+', ' ', urlopen(url).read().decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560cbaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This pulls the full text into the notebook memory. \n",
    "\n",
    "shelley_url = 'https://www.gutenberg.org/cache/epub/42324/pg42324.txt'\n",
    "shelley_text = read_url(shelley_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d47dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(shelley_text[:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b083e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "shelley_text.count('monster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a587a938",
   "metadata": {},
   "outputs": [],
   "source": [
    "#What words would you like to search for, using your by now excellent Python coding skills?\n",
    "\n",
    "print(shelley_text.count('put'), shelley_text.count('your'),shelley_text.count('words'),shelley_text.count('here'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27303a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time to get serious. Let's lose the Project Gutenberg stuff at the very start and end of the text\n",
    "\n",
    "shelley_body=shelley_text.split('*** ')[2]\n",
    "shelley_body[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e712200",
   "metadata": {},
   "outputs": [],
   "source": [
    "shelley_body[-2000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587238d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "shelley_intro=shelley_text.split('INTRODUCTION. ')[1].split('PREFACE. ')[0]\n",
    "print(shelley_intro[:100])\n",
    "print(shelley_intro[-100:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a03f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "shelley_preface=shelley_text.split('PREFACE. ')[1].split('FRANKENSTEIN;')[0]\n",
    "print(shelley_preface[:100])\n",
    "print(shelley_preface[-100:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197646dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This splits Frankenstein into chapters (splitting the text whenever the word 'CHAPTER' occurs)\n",
    "\n",
    "shelley_chapters = shelley_text.split('CHAPTER ')[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ced9c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(shelley_chapters)\n",
    "for chapter in shelley_chapters:\n",
    "  print(chapter[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc4ea49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's check the text is there by creating a wordcloud. First, we'll get some 'stopwords' installed\n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "stopwords = set(STOPWORDS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8773b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_wordcloud(data, title = None):\n",
    "    wordcloud = WordCloud(\n",
    "        background_color='white',\n",
    "        stopwords=stopwords,\n",
    "        max_words=100,\n",
    "        max_font_size=40, \n",
    "        scale=3,\n",
    "        random_state=1 # chosen at random by flipping a coin; it was heads\n",
    "    ).generate(str(data))\n",
    "\n",
    "    fig = plots.figure(1, figsize=(12, 12))\n",
    "    plots.axis('off')\n",
    "    if title: \n",
    "        fig.suptitle(title, fontsize=20)\n",
    "        fig.subplots_adjust(top=2.3)\n",
    "\n",
    "    plots.imshow(wordcloud)\n",
    "    plots.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fabe10",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_wordcloud(shelley_chapters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460bd636",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_wordcloud(shelley_chapters[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43506e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_wordcloud(shelley_chapters[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebee7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's build some graphs\n",
    "\n",
    "word_1='Elizabeth'\n",
    "word_2='Victor'\n",
    "word_3='monster'\n",
    "word_4='creature'\n",
    "word_5='devil'\n",
    "word_6='fiend'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f1da68",
   "metadata": {},
   "outputs": [],
   "source": [
    "T1_counts = {word_1: np.char.count(shelley_chapters, word_1),\n",
    "        word_2: np.char.count(shelley_chapters, word_2),\n",
    "        word_3: np.char.count(shelley_chapters, word_3),\n",
    "        word_4: np.char.count(shelley_chapters, word_4),\n",
    "        word_5: np.char.count(shelley_chapters, word_5),\n",
    "        word_6: np.char.count(shelley_chapters, word_6)}\n",
    "type(T1_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a1b5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "T1_counts_DF=pd.DataFrame(T1_counts)\n",
    "type(T1_counts_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe8e68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "T1_counts_DF['Creature']=T1_counts_DF['monster']+T1_counts_DF['creature']+T1_counts_DF['devil']+T1_counts_DF['fiend']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06128cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#These are some ways the creature might be described. Are there any more you can think of that we should add?\n",
    "\n",
    "del T1_counts_DF['monster']\n",
    "del T1_counts_DF['creature']\n",
    "del T1_counts_DF['devil']\n",
    "del T1_counts_DF['fiend']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144618b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "T1_counts_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b66ca68",
   "metadata": {},
   "outputs": [],
   "source": [
    "T1_counts_DF['Chapter']=np.arange(1,len(shelley_chapters)+1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35a68ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "T1_counts_DF.plot('Chapter')\n",
    "plots.title('Number of Times Names Appear', y=1.08);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8147fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graph of words used to describe the \"monster\"\n",
    "\n",
    "name_1='monster'\n",
    "name_2='creature'\n",
    "name_3='devil'\n",
    "name_4='fiend'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f673d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "T2_counts = {name_1: np.char.count(shelley_chapters, name_1),\n",
    "        name_2: np.char.count(shelley_chapters, name_2),\n",
    "        name_3: np.char.count(shelley_chapters, name_3),\n",
    "        name_4: np.char.count(shelley_chapters, name_4)}\n",
    "type(T2_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301550f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "T2_counts_DF=pd.DataFrame(T2_counts)\n",
    "type(T2_counts_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacc24d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "T2_counts_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61769290",
   "metadata": {},
   "outputs": [],
   "source": [
    "T2_counts_DF['Chapter']=np.arange(1,len(shelley_chapters)+1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413a7449",
   "metadata": {},
   "outputs": [],
   "source": [
    "T2_counts_DF.plot('Chapter')\n",
    "plots.title('Words used to describe the creature', y=1.08);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d128cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Words used to describe the environment. Are there any more you can think of that we should add?\n",
    "\n",
    "term_1='ice'\n",
    "term_2='cold'\n",
    "term_3='mountain'\n",
    "term_4='green'\n",
    "term_5='river'\n",
    "term_6='sublime'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257ea173",
   "metadata": {},
   "outputs": [],
   "source": [
    "T3_counts = {term_1: np.char.count(shelley_chapters, term_1),\n",
    "        term_2: np.char.count(shelley_chapters, term_2),\n",
    "        term_3: np.char.count(shelley_chapters, term_3),\n",
    "        term_4: np.char.count(shelley_chapters, term_4),\n",
    "        term_5: np.char.count(shelley_chapters, term_5),\n",
    "        term_6: np.char.count(shelley_chapters, term_6)}\n",
    "type(T3_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887b3623",
   "metadata": {},
   "outputs": [],
   "source": [
    "T3_counts_DF=pd.DataFrame(T3_counts)\n",
    "type(T3_counts_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633cd8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "T3_counts_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a807ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "T3_counts_DF['Chapter']=np.arange(1,len(shelley_chapters)+1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67859326",
   "metadata": {},
   "outputs": [],
   "source": [
    "T3_counts_DF.plot('Chapter')\n",
    "plots.title('Evironment words', y=1.08);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37addb0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
